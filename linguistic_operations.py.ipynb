{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest_aashay/.local/lib/python2.7/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "import spacy\n",
    "import nltk\n",
    "from word2number import w2n\n",
    "from find_similar import *\n",
    "\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "wvec = KeyedVectors.load_word2vec_format(\"../btp2/datasets/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "fl = open(\"small_verb.txt\")\n",
    "seedverbs = []\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "seedtype = {}\n",
    "for line in fl:\n",
    "    seedtype[line.split()[0]] = line.split()[1]\n",
    "    line = line.strip().split(\" \")[0]\n",
    "    seedverbs.append(line.split()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class linguistic_operations():\n",
    "    def __init__(self):\n",
    "        self.depRelations = []\n",
    "        self.lastrelation = []\n",
    "        self.lastGraph = []\n",
    "        self.premGraph = []\n",
    "        self.question = \"\"\n",
    "        self.ind = {}\n",
    "        self.visited = []\n",
    "        self.path_to_jar = \"./stanford-parser/stanford-parser.jar\"\n",
    "        self.path_to_models_jar = \"./stanford-parser/stanford-parser-3.4.1-models.jar\"\n",
    "        self.dependency_parser = StanfordDependencyParser(path_to_jar = self.path_to_jar, path_to_models_jar = self.path_to_models_jar)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def dependencyParse(self,sentence):\n",
    "        self.question = sentence\n",
    "        result = self.dependency_parser.raw_parse(sentence)\n",
    "        dep = result.next()\n",
    "        self.depRelations = list(dep.triples())\n",
    "        return self.depRelations\n",
    "    \n",
    "    \n",
    "    def numNoun(self):\n",
    "        allrelations = {}\n",
    "        lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "        for relation in self.depRelations:\n",
    "            if relation[1] == 'num':\n",
    "                seed = ps.stem(relation[0][0])\n",
    "                if seed not in allrelations:\n",
    "                    allrelations[seed] = []\n",
    "#                 print (\"rela = \",str(relation[2][0]))\n",
    "                allrelations[seed].append(w2n.word_to_num(str(relation[2][0])))\n",
    "        self.allrelations =  allrelations\n",
    "        return allrelations\n",
    "    \n",
    "    \n",
    "    def findroot(self):\n",
    "        for relation in self.lastrelation:\n",
    "            if relation[0][1][0]=='W':\n",
    "                return ps.stem(relation[0][0])\n",
    "            elif relation[2][1][0]=='W':\n",
    "                return ps.stem(relation[2][0])\n",
    "        return \"NAN\"\n",
    "    \n",
    "    \n",
    "    def makeGraphLast(self):\n",
    "        \n",
    "        last = nltk.sent_tokenize(self.question)[-1]\n",
    "        allwords = self.makeseedvocab(last)\n",
    "        result = self.dependency_parser.raw_parse(last)\n",
    "        dep = result.next()\n",
    "        self.lastrelation = list(dep.triples())\n",
    "#         print (self.lastrelation)\n",
    "        newRelation = []\n",
    "        for relation in self.lastrelation:\n",
    "            new = (ps.stem(relation[0][0]),relation[1],ps.stem(relation[2][0]))\n",
    "            newRelation.append(new)\n",
    "\n",
    "        \n",
    "#         print (newRelation)\n",
    "        cnt =0 \n",
    "        for token in allwords:\n",
    "            self.ind[token] = cnt\n",
    "            cnt+=1\n",
    "    \n",
    "        graph = [[] for i in range(len(allwords)) ]\n",
    "        for relation in newRelation:\n",
    "            graph[self.ind[relation[0]]].append(self.ind[relation[2]])\n",
    "            graph[self.ind[relation[2]]].append(self.ind[relation[0]])\n",
    "        self.visited = [0 for i in range(len(allwords))]\n",
    "        return graph\n",
    "            \n",
    "    \n",
    "    def dfs(self,root,graph):\n",
    "        self.visited[root] = 1\n",
    "        for i in range(len(graph[root])):\n",
    "            if self.visited[graph[root][i]]==0:\n",
    "                self.dfs(graph[root][i],graph)\n",
    "        return \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    def makeseedvocab(self,last):\n",
    "        allwords = set()\n",
    "        sentences = nltk.word_tokenize(last)\n",
    "        for word in sentences:\n",
    "            allwords.add(ps.stem(word))\n",
    "#         print (allwords)\n",
    "        return allwords\n",
    "    \n",
    "    \n",
    "    def whoseQuantity(self):\n",
    "        \n",
    "        for relation in self.lastrelation:\n",
    "#             print ps.stem(relation[0][0]),ps.stem(relation[2][0])\n",
    "            if (relation[0][1] == \"NNS\" or relation[0][1] == \"NN\") and ps.stem(relation[0][0]) in self.allrelations:\n",
    "                return ps.stem(relation[0][0])\n",
    "            elif (relation[2][1]== \"NNS\" or relation[2][1]== \"NN\") and ps.stem(relation[2][0]) in self.allrelations:\n",
    "                return ps.stem(relation[2][0])\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findtransition(linguistic,x):\n",
    "        temp = nltk.sent_tokenize(linguistic.question)\n",
    "#         for i in range \n",
    "        ll = nltk.word_tokenize(temp[-1])\n",
    "        for i in range(len(ll)) :\n",
    "            if ll[i]==\"need\" or ll[i]==\"needed\":\n",
    "                return '-'\n",
    "        sentences = temp[0:-1]\n",
    "        premsentence = \"\"\n",
    "        for i in sentences:\n",
    "            premsentence += i\n",
    "        result = linguistic.dependency_parser.raw_parse(premsentence)\n",
    "        dep = result.next()\n",
    "        deppremise = list(dep.triples())\n",
    "        for relation in deppremise:\n",
    "#             print \"relation= \" ,relation[0][1][0:2],relation[0][1][0:2]\n",
    "            if relation[0][1][0:2] ==u\"VB\":\n",
    "                print \"verb\",ps.stem(relation[0][0])\n",
    "                ms = x.most_similar(ps.stem(relation[0][0]),seedverbs,wvec)\n",
    "                print \"seedtype =\", ms,seedtype[ms]\n",
    "                if seedtype[ms] == '+' or seedtype[ms] =='-':\n",
    "                    return seedtype[ms]\n",
    "            if relation[2][1][0:2] ==u\"VB\":\n",
    "                print \"verb\",ps.stem(relation[2][0])\n",
    "                ms = x.most_similar(ps.stem(relation[2][0]),seedverbs,wvec)\n",
    "                print \"seedtype =\",ps.stem(relation[0][0]),ms,seedtype[ms]\n",
    "                if seedtype[ms] == '+' or seedtype[ms] =='-':\n",
    "                    return seedtype[ms]\n",
    "        return \"0\"\n",
    "def findanswer(allrelations,trans,qentity):\n",
    "#     print (qentity)\n",
    "    quantities = allrelations[qentity]\n",
    "    if len(quantities)==1:\n",
    "        return int(quantities[0])\n",
    "    ans =0.0\n",
    "    if trans == '+' or trans =='0':\n",
    "        for i in quantities:\n",
    "            ans+=int(i)\n",
    "    if trans == '-':\n",
    "        ans = abs(int(quantities[0])-int(quantities[1]))\n",
    "    return ans\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate(inp_sent):\n",
    "    print \"\\n--------\\n\"\n",
    "    linguistic = linguistic_operations()\n",
    "    x = linguistic.dependencyParse(inp_sent)\n",
    "    print inp_sent\n",
    "    allrelation = linguistic.numNoun()\n",
    "    print allrelation\n",
    "    graph = linguistic.makeGraphLast()\n",
    "    qentity = linguistic.whoseQuantity()\n",
    "#     print (\"qentity \" ,qentity)\n",
    "    x = find_similar()\n",
    "    trans = findtransition(linguistic,x)\n",
    "    return findanswer(allrelation,trans,qentity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qfl = open(\"questions.txt\")\n",
    "questions = []\n",
    "for line in qfl:\n",
    "    ans = calculate(line.split(\"||\")[0].strip())\n",
    "    if int(ans) == int(line.split(\"||\")[1]):\n",
    "        print ans,\"1\"\n",
    "    else:\n",
    "        print ans,\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:12: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.StanforCoreNLPDependencyParser\u001b[0m instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have three books and four pens . How many books do I have now?\n",
      "{u'pen': [4], u'book': [3]}\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "3\n",
      "\n",
      "--------\n",
      "\n",
      "I have 3 books and 4 pens. I gave 1 book to Tom. How many books do I have now?\n",
      "{u'pen': [4], u'book': [3, 1]}\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb gave\n",
      "seedtype = have give -\n",
      "2\n",
      "\n",
      "--------\n",
      "\n",
      "I have 3 books and 4 pens. I got 1 more book. How many books do I have now?\n",
      "{u'pen': [4], u'book': [3, 1]}\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb have\n",
      "seedtype = have 0\n",
      "verb got\n",
      "seedtype = have get +\n",
      "4.0\n",
      "\n",
      "--------\n",
      "\n",
      "Mary is baking a cake . The recipe wants 8 cups of flour . She already put in 2 cups . How many cups does she need to add ?\n",
      "{u'cup': [8, 2]}\n",
      "6\n",
      "\n",
      "--------\n",
      "\n",
      "Sara 's high school played 12 games this year . The team won most of their games . They were defeated during 4 games . How many games did they win ?\n",
      "{u'game': [12, 4]}\n",
      "verb defeat\n",
      "seedtype = defeat -\n",
      "8\n",
      "\n",
      "--------\n",
      "\n",
      "There were 6 roses in the vase . Mary cut some roses from her flower garden . There are now 16 roses in the vase . How many roses did she cut ?\n",
      "{u'rose': [6, 16]}\n",
      "verb are\n",
      "seedtype = be 0\n",
      "verb were\n",
      "seedtype = are be 0\n",
      "verb were\n",
      "seedtype = be 0\n",
      "verb were\n",
      "seedtype = be 0\n",
      "verb cut\n",
      "seedtype = rose cut -\n",
      "10\n",
      "\n",
      "--------\n",
      "\n",
      "Joan went to 4 games this year . She went to 9 games last year . How many games did Joan go to in all ?\n",
      "{u'game': [4, 9]}\n",
      "verb went\n",
      "seedtype = travel +\n",
      "13.0\n",
      "\n",
      "--------\n",
      "\n",
      "Tom has 9 balloons Sara has 8 balloons . How many balloons do they have in total ?\n",
      "{u'balloon': [9, 8]}\n",
      "verb ha\n",
      "seedtype = harvest +\n",
      "17.0\n",
      "\n",
      "--------\n",
      "\n",
      "There are 4 trees currently in the park . Park workers will plant 6 trees today . How many trees will the park have when the workers are finished ?\n",
      "{u'tree': [4, 6]}\n",
      "verb plant\n",
      "seedtype = shop +\n",
      "10.0\n",
      "\n",
      "--------\n",
      "\n",
      "Sam had 9 dimes in his bank . He gave 7 dimes to someone. How many dimes does Sam have now ?\n",
      "{u'dime': [9, 7]}\n",
      "verb gave\n",
      "seedtype = give -\n",
      "2\n",
      "\n",
      "--------\n",
      "\n",
      "Tom had 5 pencils. He placed 3 pencils in the drawer . How many pencils are remaining ?\n",
      "{u'pencil': [5, 3]}\n",
      "verb had\n",
      "seedtype = have 0\n",
      "verb had\n",
      "seedtype = have 0\n",
      "verb place\n",
      "seedtype = pencils.h put -\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print calculate(\"I have three books and four pens . How many books do I have now?\")\n",
    "print calculate(\"I have 3 books and 4 pens. I gave 1 book to Tom. How many books do I have now?\")\n",
    "print calculate(\"I have 3 books and 4 pens. I got 1 more book. How many books do I have now?\")\n",
    "print calculate(\"Mary is baking a cake . The recipe wants 8 cups of flour . She already put in 2 cups . How many cups does she need to add ?\")\n",
    "print calculate(\"Sara 's high school played 12 games this year . The team won most of their games . They were defeated during 4 games . How many games did they win ?\")\n",
    "print calculate(\"There were 6 roses in the vase . Mary cut some roses from her flower garden . There are now 16 roses in the vase . How many roses did she cut ?\")\n",
    "print calculate(\"Joan went to 4 games this year . She went to 9 games last year . How many games did Joan go to in all ?\")\n",
    "print calculate(\"Tom has 9 balloons Sara has 8 balloons . How many balloons do they have in total ?\")\n",
    "print calculate(\"There are 4 trees currently in the park . Park workers will plant 6 trees today . How many trees will the park have when the workers are finished ?\")\n",
    "print calculate(\"Sam had 9 dimes in his bank . He gave 7 dimes to someone. How many dimes does Sam have now ?\")\n",
    "print calculate(\"Tom had 5 pencils. He placed 3 pencils in the drawer . How many pencils are remaining ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
